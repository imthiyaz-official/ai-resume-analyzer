{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e011be-b674-4504-8992-ef7cbddce8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ccfe5e-eb1f-4642-b498-da6a355141d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('UpdatedResumeDataSet[1].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9c9c6-b542-4e28-acce-a327c8460ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38a7b81-f580-4f06-acc2-375f094e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ebd1dc-f47f-4c7b-bb96-6f6843ef9f94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3732da8-b3ab-4e73-b699-051f832ff008",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "total = len(df)\n",
    "role_counts = df['Category'].value_counts()\n",
    "plt.figure(figsize=(18,16))\n",
    "plt.subplot(2, 1, 1)\n",
    "ax = sns.countplot(\n",
    "    y='Category',\n",
    "    data=df,\n",
    "    order=role_counts.index)\n",
    "for p in ax.patches:\n",
    "    percent = f'{(p.get_width() / total) * 100:.1f}%'\n",
    "    ax.text(\n",
    "        p.get_width() + 0.5,\n",
    "        p.get_y() + p.get_height() / 2,\n",
    "        percent,\n",
    "        va='center')\n",
    "plt.title(\"All Job Roles Distribution (Bar Chart)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Job Role\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.pie(\n",
    "    role_counts.values,\n",
    "    labels=role_counts.index,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=140)\n",
    "plt.title(\"All Job Roles Distribution (Pie Chart)\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223714a1-2e2c-4d40-9f4b-7ef397e6dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "top10 = df['Category'].value_counts().head(10)\n",
    "total_top10 = top10.sum()\n",
    "plt.figure(figsize=(12,14))\n",
    "plt.subplot(2, 1, 1)\n",
    "ax = sns.barplot(\n",
    "    x=top10.values,\n",
    "    y=top10.index)\n",
    "for i, v in enumerate(top10.values):\n",
    "    percent = f'{(v / total_top10) * 100:.1f}%'\n",
    "    ax.text(v + 0.5, i, percent, va='center')\n",
    "plt.title(\"Top 10 Job Categories (Bar Graph)\")\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.pie(\n",
    "    top10.values,\n",
    "    labels=top10.index,\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=140,\n",
    "    wedgeprops={'edgecolor': 'black'})\n",
    "plt.title(\"Top 10 Job Categories (Pie Chart)\")\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b4f99-6dfa-4c4e-91de-ee296c2bc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Category'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b7852-7242-4046-ac71-012eda92f50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resume'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4706a257-eb39-475c-b3ee-f69dba85f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"     \n",
    "    text = re.sub(r'http\\S+', ' ', text)          # remove URLs\n",
    "    text = re.sub(r'RT|cc', ' ', text)             # remove RT, cc\n",
    "    text = re.sub(r'#\\S+', ' ', text)              # remove hashtags\n",
    "    text = re.sub(r'@\\S+', ' ', text)              # remove mentions\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', ' ', text)      # remove non-ASCII\n",
    "    text = re.sub(r'[!\"#$%&\\'()*+,-./:;<=>?@[\\\\\\]^_`{|}~]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)               # remove extra spaces\n",
    "    return text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b3b1b4-2b84-4e2a-9774-13be6d166106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resume'] = df['Resume'].apply(cleanResume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa3f72-bef5-48c6-93e0-94305fe9247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Resume'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d87e2f-414e-43a4-b782-12704f83a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "le.fit(df['Category'])\n",
    "df['Category'] = le.transform(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6207202c-4339-47ba-9d75-019b958aef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b9ef1-afcb-4f82-afcc-be6cdfd2b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tfidf.fit(df['Resume'])\n",
    "requredText  = tfidf.transform(df['Resume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74304e0-1f26-45f2-95be-2749c92bb217",
   "metadata": {},
   "outputs": [],
   "source": [
    "requredText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56cb2a6-617d-4e5f-9ce3-451af6988e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f0797-d1bc-4263-b388-9e7631f1de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(requredText, df['Category'], test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bbe1b-8c2e-40ff-903b-705863c97d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2af90c4-8b44-436d-bdfb-912e7ad92261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Ensure that X_train and X_test are dense if they are sparse\n",
    "X_train = X_train.toarray() if hasattr(X_train, 'toarray') else X_train\n",
    "X_test = X_test.toarray() if hasattr(X_test, 'toarray') else X_test\n",
    "\n",
    "# 1. Train KNeighborsClassifier\n",
    "knn_model = OneVsRestClassifier(KNeighborsClassifier())\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "print(\"\\nKNeighborsClassifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_knn)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_knn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cde767-85f2-463c-aec3-aa54f1612b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = OneVsRestClassifier(SVC())\n",
    "svc_model.fit(X_train, y_train)\n",
    "y_pred_svc = svc_model.predict(X_test)\n",
    "print(\"\\nSVC Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svc):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_svc)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_svc)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619215df-e82b-4153-87af-cac210fd875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = OneVsRestClassifier(RandomForestClassifier())\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(\"\\nRandomForestClassifier Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred_rf)}\")\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a976a-f7ae-4fbf-bff1-5c06ecde393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(tfidf,open('tfidf.pkl','wb'))\n",
    "pickle.dump(svc_model, open('clf.pkl', 'wb'))\n",
    "pickle.dump(le, open(\"encoder.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833a4f81-0173-4ff9-8514-da7d9e0b369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the category of a resume\n",
    "def pred(input_resume):\n",
    "    # Preprocess the input text (e.g., cleaning, etc.)\n",
    "    cleaned_text = cleanResume(input_resume) \n",
    "\n",
    "    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training\n",
    "    vectorized_text = tfidf.transform([cleaned_text])\n",
    "    \n",
    "    # Convert sparse matrix to dense\n",
    "    vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "    # Prediction\n",
    "    predicted_category = svc_model.predict(vectorized_text)\n",
    "\n",
    "    # get name of predicted category\n",
    "    predicted_category_name = le.inverse_transform(predicted_category)\n",
    "\n",
    "    return predicted_category_name[0]  # Return the category name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6848f-026a-4fe2-922a-33649be0c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "myresume = \"\"\"\n",
    "SYED IMTHIYAZ\n",
    "+91 9550730829\n",
    "Gurramkonda, Madanapalle, Andhra Pradesh\n",
    "syedimthiyaz456@gmail.com\n",
    "linkedin.com/in/syed-imthiyaz\n",
    "github.com/imthiyaz-official\n",
    "\n",
    "PROFESSIONAL SUMMARY\n",
    "Computer Science undergraduate with strong skills in Python, SQL, and data analysis.\n",
    "Experienced in exploratory data analysis (EDA), data cleaning, and feature engineering,\n",
    "with hands-on experience using Pandas, NumPy, Matplotlib, and Seaborn.\n",
    "Proficient in building interactive dashboards using Power BI and Tableau, and familiar with\n",
    "AWS cloud services (EC2, S3, IAM).\n",
    "Seeking entry-level Data Analyst or Data Science roles to apply analytical,\n",
    "statistical, and problem-solving skills to real-world business problems.\n",
    "\n",
    "SKILLS\n",
    "Programming: Python, Java (Basics)\n",
    "Data Analysis: EDA, Data Wrangling, Data Cleaning, Feature Engineering\n",
    "Statistics: Descriptive Statistics, Probability, Hypothesis Testing\n",
    "Machine Learning: Regression, Classification, Model Evaluation\n",
    "Databases: SQL (Joins, Subqueries, Aggregations), PostgreSQL\n",
    "Visualization: Power BI, Tableau, Seaborn\n",
    "Libraries: Pandas, NumPy, Scikit-learn\n",
    "Tools: Git, GitHub, Jupyter Notebook, Google Colab, VS Code, PyCharm\n",
    "Cloud: AWS (EC2, S3, IAM)\n",
    "Core CS: Data Structures, Operating Systems, Computer Networks, OOP\n",
    "Interpersonal Skills: Communication, Team Collaboration, Active Listening\n",
    "Professional Skills: Problem Solving, Analytical Thinking, Adaptability, Time Management\n",
    "\n",
    "PROJECTS\n",
    "Real-Time Hand Tracking System\n",
    "Python, OpenCV, Tkinter\n",
    "Developed a Python-based real-time computer vision system using OpenCV with multithreaded\n",
    "camera capture.\n",
    "Optimized frame processing to improve stability and reduce latency by 25 percent.\n",
    "\n",
    "IPL Cricket Analysis Dashboard\n",
    "Power BI, DAX, Data Modeling\n",
    "Analyzed 60000 plus IPL match records from 2008 to 2025 and built an interactive dashboard.\n",
    "Designed KPIs, slicers, and advanced DAX measures to identify team and player performance trends.\n",
    "\n",
    "Food Habits Awareness Community Service Project\n",
    "Conducted a structured survey of 100 plus participants to analyze dietary habits and nutritional gaps.\n",
    "Presented data-driven insights through awareness sessions to promote healthy food practices.\n",
    "\n",
    "INTERNSHIP\n",
    "Cloud Technology Intern AWS\n",
    "Saraj Innotech Services Pvt Ltd\n",
    "May 2025 to July 2025\n",
    "Configured and managed AWS EC2, S3, and IAM services, reducing setup time by 20 percent.\n",
    "Automated S3 backup and file management processes, cutting manual effort by 40 percent.\n",
    "Optimized cloud resource usage using monitoring and networking tools.\n",
    "Documented cloud configurations to support team collaboration and maintenance.\n",
    "\n",
    "CERTIFICATIONS\n",
    "Python Complete Course Udemy\n",
    "Data Analysis and Decision Making NPTEL\n",
    "NumPy for Data Science Udemy\n",
    "Power BI Certification Infosys Springboard\n",
    "Master Data Science and Machine Learning Masterclass GUVI and HCL\n",
    "Machine Learning and Artificial Intelligence Beginners Course Udemy\n",
    "Cloud Technology AWS Certification Saraj Innotech Services Pvt Ltd APSCHE and AICTE\n",
    "\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0350f4-7f80-4bf8-b95b-2091a4dbcd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred(myresume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603ee30-0eea-4305-819c-44ebec487c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
